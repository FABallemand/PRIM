\chapter{State of the Art}
\label{sota}
\acrfull{lic} is a lossy compression method based on machine learning. Using autoencoder architecture, it is possible to build and train end-to-end a neural network that achieves balance between image compression efficiency and reconstruction fidelity. \acrshort{lic} consists of three successive steps: projection in a low-dimensional latent space (using the encoder part of the autoencoder), quantisation and lossless entropy coding. Decompression is achieved by applying entropy decoding and projecting the result back into the image space with the decoder part of the autoencoder. \cite{licmedium, licstanford}

Early seminal works accounted for a unique latent representation modelled with a fully factored distribution.\cite{ballé2017endtoendoptimizedimagecompression} Since then, much of the research in the field has focused on improving the compression efficiency by refining the entropy model. This basic scheme was then improved by introducing an auxiliary latent space called hyperprior capturing spatial correlation within the image, furthering compression efficiency.\cite{ballé2018variationalimagecompressionscale} \acrshort{lic} has shown the ability to outperform standardised video codecs in compression efficiency, fostering the demand for embedded hardware implementations.

Applying frugal machine learning techniques can help reducing the load of the neural network on the computer. Such methods include pruning, quantisation or knowledge distillation.\cite{touvron2021trainingdataefficientimagetransformers} It should be noted that knowledge distillation can be achieved between different architecture opening the possibility to use a completely different network for decoding.\cite{liu2022crossarchitectureknowledgedistillation}

Achieving realtime coding on resource constrained platforms such as FPGAs demands ad-hoc design choices
such as in the state of the art \acrshort{lic} implementations. However, FPGA implementations have
been lagging behind recent research in \acrshort{lic} due to the increasing complexity of implementing in hardware recent \acrshort{lic} models. For example, further improves the RD efficiency by introducing s\acrshort{lic}e-based latent channel conditioning and latent residual prediction with an approach suitable for parallel execution. The RD efficiency is further boosted in the work of Zou et al.\cite{zou2022devildetailswindowbasedattention} by introducing a Window Attention Module in the autoencoder architecture and experimenting with a transformer-based architecture in place of the traditional convolutional architecture.