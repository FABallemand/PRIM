\chapter{State-of-the-art}
\label{sota}

\section{Learned Image Compression}
\acrfull{lic} is a lossy compression method based on machine learning. Using autoencoder architecture, it is possible to build and train from end-to-end a neural network that achieves balance between image compression efficiency and reconstruction fidelity. \acrshort{lic} consists of three successive steps: projection in a low-dimensional latent space (using the encoder part of the autoencoder), quantisation and lossless entropy coding. Decompression is achieved by applying entropy decoding and projecting the result back into the image space with the decoder part of the autoencoder \cite{licmedium, licstanford}.

This approach is inspired by transform coding, a signal processing method that consists of three steps: applying an invertible transformation to a signal, quantizing the transformed data to achieve a compact representation, and inverting the transform to recover an approximation of the original signal. This method is used by most deterministic image compression algorithms like JPEG and JPEG-2000.

In 2016, Ballé et al. \cite{ballé2016endtoendoptimizationnonlineartransform} propose the first end-to-end optimised image compression framework. Inspired by the field of object and pattern recognition, the framework leverages end-to-end optimisation to achieve better results than previous systems that were built by manually combining a sequence of individually designed and optimized processing stages. Still based on transform coding, the framework consists in transforming an image vector from the signal domain to a code domain vector using a differentiable nonlinear transformation (analysis transform) and applying scalar quantisation to achieve the compressed image. The code domain vector can be transformed back to the signal domain thanks to another differentiable nonlinear transformation (synthesis transform). Contrary to traditional methods, the synthesis transform is not necessariliy the exact inverse of the analysis transform as the system is jointly optimized over large datasets with the goal of minimising the \acrfull{rd} loss. The rate is measured by the entropy of the quantized vector and the distortion, usually measured using \acrshort{mse} or \acrshort{psnr} in the signal space is evaluated with either \acrshort{mse} or \acrfull{nlp} after applying a suitable perceptual transform to achieve better approximation of perceptual visual distortion. The authors propose transformations based on \acrfull{gdn} (and its approximate inverse) and to use additive uniform noise at training time to preserve the system differentiability. The first experiments conducted with this framework show substantial improvements in bit rate and perceptual appearance compared to previous linear transform coding techniques.

A few months later, Ballé et al. improve the framework \cite{ballé2017endtoendoptimizedimagecompression}. Based on the same three-step transform coding method (linear transformation, quantization, lossless entropy coding) as deterministic image compression algorithms, the proposed model uses a nonlinear analysis transformation, a uniform quantizer and a lossless entropy coding. It should be noted that the analysis transformation is inspired by biological visual systems and made of convolutions and nonlinear activation functions (\acrshort{gdn}). By replacing quanitization by additive uniform noise at training time (where quantization would have cancelled gradients), the model is jointly optimised for \acrshort{rd} performance using bit rate\footnote{The appropirate measure in the context of image compression.} (instead of entropy) and \acrshort{mse}. Although optimizing the model for a measure of perceptual distortion, would have exhibited visually superior performance, \acrshort{mse} was used in order to facilitate comparison with related works (usually trained with \acrshort{mse}) and because there was no reliable perceptual metric for color images. This novel framework yields unperfect but impressive results: details are lost in compression but it does not suffer from artifacts like JPEG and JPEG-2000. It outperforms JPEG and JPEG-2000 at all bit rates both perceptually and quantitatively according to \acrshort{psnr} and \acrshort{msssim} measures thanks to its ability of progressively reducing the image quality.

Driven by the interest of the machine learning and image processing communities in machine learning methods for lossy image compression, Ballé et al. extend their end-to-end trainable model for image compression presented in \cite{ballé2017endtoendoptimizedimagecompression} with side information \cite{ballé2018variationalimagecompressionscale}. Conventional image compression codecs increase their compression performance by sending additional information from the encoder to the decoder. Commonly named side information, it is usually hand designed in these codecs. Using the same formalism as \acrshort{vae}s, the authors introduce a more powerful entropy model which acts as a \acrshort{vae} on the latent representation. In other words, it is a prior on the parameters of the entropy model (hyperprior) that is jointly learnt with the main autoencoder and can be interpreted as side information. This side information is particularly useful as the marginal for an image is likely to be different from the marginal for the ensemble of training images. The additional side information (not seen during training) is valuable for the decoder to reduce mismatch. Once again using the relaxation of the problem (using additive noise instead of quantisation at training time), the authors train different models with and without hyperprior optimised for \acrshort{mse} or \acrshort{msssim} reconstruction loss and for different \acrshort{rd} tradeoffs. \acrshort{psnr} results show that the hyperprior model optimised for \acrshort{mse} consistently outperforms all others \acrshort{lic} methods and performs on par with heavily optimised BGP algorithm. When optimised for \acrshort{msssim}, the hyperprior model is even able to provide better results than state-of-the-art method at all bit rates. The distinction between \acrshort{mse} and \acrshort{msssim} optimised results is relevant as neither have understanding of the semantic meaning of the image, leading to perceptual preferences depending of the image. \acrshort{msssim}, based on human visibility threshold and contrast, attenuates the error in image regions with high contrast, and boosts the error in regions with low contrast yielding good results on images with a lot of textures (like grass) but unsatisfactory results on meaningful high contrast areas like text.

Inspired by success of autoregressive prior in generative models, Ballé et al. extend their previous work \cite{minnen2018jointautoregressivehierarchicalpriors}. They generalise hierarchical Gaussian Scale Mixture model to Gaussian Mixture model and add an autoregressive component. The autoregressive components captures the context of each pixel, that is to say is allows the model to find spacial dependencies in the image leading to improved image reconstruction. The authors highlight the fact that dimensionality reduction is different from compression. It consists in reducing the entropy of the representation under a prior probability model shared between the sender and the receiver, not only the dimensionality. Experimental results show that the end-to-end optimisation of the model can learn the optimal bottleneck size: if the bottleneck size is large enough, the same latent value is generated and a probability of 1 is assigned for useless channels. This wastes computation but requires no additional entropy. Conversely, small sizes of bottleneck can impact \acrshort{rd} performance. When optimised for \acrshort{msssim}, the proposed model outperforms all conventional and \acrshort{nn} based methods in both \acrshort{psnr} and \acrshort{msssim} (including BPG) in \acrshort{rd} performance as well as visual results.

Early seminal works accounted for a unique latent representation modelled with a fully factored distribution. Since then, much of the research in the field has focused on improving the compression efficiency by refining the entropy model. This basic scheme was then improved by introducing an auxiliary latent space called hyperprior capturing spatial correlation within the image, furthering compression efficiency. \acrshort{lic} has shown the ability to outperform standardised video codecs in compression efficiency, fostering the demand for embedded hardware implementations.

\section{Knowledge Distillation}
Applying frugal machine learning techniques can help reducing the load of the neural network on the computer. Such methods include pruning, quantisation or knowledge distillation \cite{touvron2021trainingdataefficientimagetransformers}. The latter being particularly well suited for \acrshort{lic} as it allows to train a small model to achieve the same performances as a larger one. It should be noted that knowledge distillation can be achieved between different architecture opening the possibility to use a completely different network for decoding \cite{liu2022crossarchitectureknowledgedistillation}.

Originally created to achieve the same results than ensemble of models with a lower computational cost, Hinton et al. \cite{hinton2015distillingknowledgeneuralnetwork} propose knowledge distillation. This novel technique consists in transferring the knowledge of a cumbersome model into a single smaller one. In this approach the knowledge of a neural network is not represented by its weights but by the vector to vector mapping it has learned. A large "teacher" model can be trained with unlimited computing power for a long time on large datasets, then a smaller "student" model can learn the mapping of the teacher by using teh teacher's predictions as soft targets. This is different than training a smaller model alone, as the student model has a higher ability to generalize while requiring fewer and possibly unlabelled data. To compensate the lack of entropy (information) of the soft targets of simple tasks, the authors propose to use a temperature parameter to soften the teacher model output distribution.

In the context of LIC, it is often assumed that the encoding task is performed on a single sender with unlimited resources. The latent representation is then broadcasted and decoded on many receivers with various constrains such as time (latency) and computing resources. Leveraging KD, a smaller and more efficient decoder can be trained while maintaining visual fidelity. Noting that GAN-based LIC frameworks (like state-of-the-art HiFiC) are able to reproduce texture using large general purpose networks, the approach proposed by Helminger et al. \cite{helminger2022microdosingknowledgedistillationgan} overfits a smaller decoder network for every sequence of images that can be sent alongside the latents (more precisely only the blocs responsible of the texture decompression are replaced by a smaller bloc). The smaller decoder is trained using KD on the encoder side. This approach dramatically reduces the decoder model size and the decoding time while providing a great image quality.

More recently, Fu et al. \cite{fu2023fasthighperformancelearnedimage} propose four techniques to improve LIC with resource cautious decoders. They first improve standard LIC by using deformable convolution (convolution with a deformable receptive field) that helps extracting better features and representing objects. Then, a checkerboard context model is used to increase parallelism execution and a three-step KD method is used to reduce the decoder complexity (train teacher, train student with same architecture of the teacher jointly with the teacher, perform ablation on less relevant blocs of the student decoder and re-train jointly with teacher). Finally, L1 regularisation is introduced to make the latent representation sparser allowing to speed up decoding by only encoding non-zero channels in the encoding and decoding process, which can greatly reduce the encoding and decoding time at the cost of coding performance. The experimental results presented by the authors show better performance than traditional codes and state-of-the-art LIC methods in both image quality and encoding-decoding time.

\section{Other Related Works}
Achieving real-time coding on resource constrained platforms such as \acrshort{fpga} demands ad-hoc design choices such as in the state-of-the-art \acrshort{lic} implementations \cite{9745965, 10494759}. However, \acrshort{fpga} implementations have been lagging behind recent research in \acrshort{lic} due to the increasing complexity of implementing in hardware recent \acrshort{lic} models. For example, \cite{minnen2020channelwiseautoregressiveentropymodels} further improves the \acrshort{rd} efficiency by introducing slice-based latent channel conditioning and latent residual prediction with an approach suitable for parallel execution. The \acrshort{rd} efficiency is further boosted in the work of Zou et al. \cite{zou2022devildetailswindowbasedattention} by introducing a Window Attention Module in the autoencoder architecture and experimenting with a transformer-based architecture in place of the traditional convolutional architecture.